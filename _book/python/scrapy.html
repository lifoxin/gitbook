
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>scrapy · felix</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        
        <meta name="identifier" content="felix" scheme="ISBN">
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="class.html" />
    
    
    <link rel="prev" href="django.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    介绍
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="../linux/linux.html">
            
                <a href="../linux/linux.html">
            
                    
                    linux
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="../linux/server.html">
            
                <a href="../linux/server.html">
            
                    
                    server
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="../linux/shell.html">
            
                <a href="../linux/shell.html">
            
                    
                    shell
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="../linux/nginx.html">
            
                <a href="../linux/nginx.html">
            
                    
                    nginx
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6" data-path="../linux/iptable.html">
            
                <a href="../linux/iptable.html">
            
                    
                    iptable
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7" data-path="../linux/ansible.html">
            
                <a href="../linux/ansible.html">
            
                    
                    ansible
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8" data-path="../linux/proxy.html">
            
                <a href="../linux/proxy.html">
            
                    
                    proxy
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9" data-path="../linux/docker.html">
            
                <a href="../linux/docker.html">
            
                    
                    docker
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10" data-path="python.html">
            
                <a href="python.html">
            
                    
                    python
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.11" data-path="django.html">
            
                <a href="django.html">
            
                    
                    django
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.12" data-path="scrapy.html">
            
                <a href="scrapy.html">
            
                    
                    scrapy
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.13" data-path="class.html">
            
                <a href="class.html">
            
                    
                    class
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.14" data-path="../devops/mysql.html">
            
                <a href="../devops/mysql.html">
            
                    
                    mysql
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.15" data-path="../devops/redis.html">
            
                <a href="../devops/redis.html">
            
                    
                    redis
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.16" data-path="../devops/MongoDB.html">
            
                <a href="../devops/MongoDB.html">
            
                    
                    mongodb
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.17" data-path="../devops/jupyter.html">
            
                <a href="../devops/jupyter.html">
            
                    
                    jupyter
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.18" data-path="../devops/github.html">
            
                <a href="../devops/github.html">
            
                    
                    github
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.19" data-path="../devops/gitbook.html">
            
                <a href="../devops/gitbook.html">
            
                    
                    gitbook
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.20" data-path="../devops/golang.html">
            
                <a href="../devops/golang.html">
            
                    
                    golang
            
                </a>
            

            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >scrapy</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <p><strong>&#x521B;&#x5EFA; project</strong></p>
<p>scrapy startproject example   </p>
<p><strong>&#x521B;&#x5EFA;&#x9879;&#x76EE;quotes</strong></p>
<p>cd example</p>
<p>scrapy genspider quotes quotes.com</p>
<p><strong>&#x6267;&#x884C; scrapy</strong></p>
<p>scrapy crawl quotes -o quotes.{jl,json,csv}  --nolog</p>
<p><strong>&#x4EA4;&#x4E92;scrapy</strong></p>
<p>scrapy shell <a href="http://quotes.toscrape.com" target="_blank">http://quotes.toscrape.com</a></p>
<p>resquest = scrapy.Request(url)</p>
<p>fetch(request)</p>
<p>response.xpath(&apos;//a/@href&apos;).extract()</p>
<p><strong>xpath&#x9009;&#x62E9;&#x5668;</strong></p>
<p>//div[@class=&quot;info&quot;]/span/text()</p>
<p>//div[@class=&quot;info&quot;]//a/@href</p>
<p>//*[contains(@class,&quot;info&quot;) and contains(@class,info2)]//h1//text()</p>
<p><strong>css&#x9009;&#x62E9;&#x5668;</strong> </p>
<table>
<thead>
<tr>
<th>&#x5B50;&#x8282;</th>
<th>&#x610F;&#x4E49;</th>
</tr>
</thead>
<tbody>
<tr>
<td>.intro</td>
<td>&#x4EE3;&#x8868;class=&quot;intro&quot;</td>
</tr>
<tr>
<td>.intro .intro1</td>
<td>&#x4EE3;&#x8868;class &#x4E0B;&#x7684; class</td>
</tr>
<tr>
<td>#id</td>
<td>&#x4EE3;&#x8868; id=&quot;id&quot;</td>
</tr>
<tr>
<td>p</td>
<td>&#x4EE3;&#x8868;p</td>
</tr>
<tr>
<td>div,p</td>
<td>&#x4EE3;&#x8868;&#x6240;&#x6709;div&#x548C;p</td>
</tr>
<tr>
<td>div p</td>
<td>&#x4EE3;&#x8868;div &#x4E0B;&#x7684; p</td>
</tr>
<tr>
<td>a::attr(title)</td>
<td>&#x4EE3;&#x8868;a&#x6807;&#x7B7E;&#x4E0B;&#x7684;title&#x6807;&#x7B7E;</td>
</tr>
<tr>
<td>a::text</td>
<td>&#x4EE3;&#x8868;a&#x6807;&#x7B7E;&#x4E0B;&#x7684;&#x6240;&#x6709;&#x6587;&#x672C;</td>
</tr>
</tbody>
</table>
<p><strong>xpath&#x3001;css&#x3001;re &#x4E32;&#x8054;&#x4F7F;&#x7528;</strong></p>
<p>response.css(&apos;#id&apos;).xpath(&apos;text()&apos;).re(&apos;[.0-9]+&apos;)</p>
<p><strong>pipeline &#x6587;&#x4EF6;</strong></p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> scrapy
<span class="hljs-keyword">import</span> MySQLdb

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ValidateItem</span>:</span>    <span class="hljs-comment">#&#x53BB;&#x91CD;&#x6709;&#x6548;&#x6570;&#x636E;</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">process_item</span><span class="hljs-params">(self,item,spider)</span>:</span>
        <span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> item.fields.keys():
            <span class="hljs-keyword">if</span> key <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> item:
                print(<span class="hljs-string">&apos;item dropped&apos;</span>)
                <span class="hljs-keyword">raise</span> scrapy.exceptions.DropItem(<span class="hljs-string">&apos;key %s is missing&apos;</span> % key)
            val = item[key]
            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> isinstance(val,str):
                print(<span class="hljs-string">&apos;item dropped&apos;</span>)
                <span class="hljs-keyword">raise</span> scrapy.exceptions.DropItem(<span class="hljs-string">&apos;value %s is not str&apos;</span> %val)
        <span class="hljs-keyword">return</span> item

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TextWriterPipeline</span>:</span>  <span class="hljs-comment">#&#x5199;&#x5165;&#x6587;&#x672C;</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">open_spider</span><span class="hljs-params">(self,spider)</span>:</span>
        self.file = open(<span class="hljs-string">&apos;items.txt&apos;</span>,<span class="hljs-string">&apos;w&apos;</span>)
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">close_spider</span><span class="hljs-params">(self,spider)</span>:</span>
        self.file.close()
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">process_item</span><span class="hljs-params">(self,item,spider)</span>:</span>
        <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> [<span class="hljs-string">&apos;text&apos;</span>,<span class="hljs-string">&apos;author&apos;</span>,<span class="hljs-string">&apos;tags&apos;</span>]:
            value = item[k]
            self.file.write(<span class="hljs-string">&apos;%s: %s\n&apos;</span> % (k,value)
        self.file.write(<span class="hljs-string">&apos;\n&apos;</span>)
        <span class="hljs-keyword">return</span> item

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MysqlPipeline</span>:</span>  <span class="hljs-comment">#&#x5199;&#x5165;&#x6570;&#x636E;&#x5E93;</span>
<span class="hljs-meta">    @classmethod     #&#x5B9E;&#x4F8B;&#x5316;&#x7C7B;&#xFF0C;&#x901A;&#x8FC7;crawler&#x5F15;&#x64CE;&#x8C03;&#x7528;setting</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">from_crawler</span><span class="hljs-params">(cls,crawler)</span>:</span>
        user = crawler.settings.get(<span class="hljs-string">&apos;USER&apos;</span>)
        password = crawler.settings.get(<span class="hljs-string">&apos;PASSWORD&apos;</span>)
        database = crawler.settings.get(<span class="hljs-string">&apos;DATABASE&apos;</span>)
        charset = crawler.settings.get(<span class="hljs-string">&apos;CHARSET&apos;</span>)
        dbtable = crawler.settings.get(<span class="hljs-string">&apos;DBTABLE&apos;</span>)
        <span class="hljs-keyword">return</span> cls(user,password,database,charset,dbtable)
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self,user,password,database,charset,dbtable)</span>:</span>
        self.user = user
        self.password = password
        self.database = database
        self.charset = charset
        self.dbtable = dbtable
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">open_spider</span><span class="hljs-params">(self,spider)</span>:</span>
        self.conn = MySQLdb.connect(user=<span class="hljs-string">&apos;self.user&apos;</span>,passwd=<span class="hljs-string">&apos;self.password&apos;</span>,
                                    database=<span class="hljs-string">&apos;self.database&apos;</span>,charset=<span class="hljs-string">&apos;self.utf8&apos;</span>)
        self.cursor = self.conn.cursor()
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">close_spider</span><span class="hljs-params">(self,spider)</span>:</span>
        self.conn.commit()
        self.conn.close()
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">process_item</span><span class="hljs-params">(self,item,spider)</span>:</span>
        sql = <span class="hljs-string">&apos;insert into quotes values (%s,%s,%s)&apos;</span>
        data = (item[<span class="hljs-string">&apos;text&apos;</span>,item[<span class="hljs-string">&apos;author&apos;</span>],item[<span class="hljs-string">&apos;tags&apos;</span>]]
        self.cursor.execute(sql,args=data)
        <span class="hljs-keyword">return</span> item
</code></pre>
<p><strong>MiddleWare &#x6587;&#x4EF6;</strong></p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> random
<span class="hljs-keyword">from</span> scrapy.downloadermiddlewares.useragent <span class="hljs-keyword">import</span> UserAgentMiddleware

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">FilterOutUrl</span>:</span>  <span class="hljs-comment">#&#x8FC7;&#x6EE4;&#x6389;&#x4E0D;&#x662F;&#x4EE5;page&#x5F00;&#x5934;&#x7684;url</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">process_spider_output</span><span class="hljs-params">(self,response,result,spider)</span>:</span>
        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> result:
            path =<span class="hljs-string">&apos;/&apos;</span> + <span class="hljs-string">&apos;/&apos;</span>.join(i.url.split(<span class="hljs-string">&apos;/&apos;</span>)[<span class="hljs-number">3</span>:])
            <span class="hljs-comment"># &#x5982;&#x679C; allowed_paths &#x4E0D;&#x5B58;&#x5728;&#xFF0C;&#x6216;&#x8005;None,&#x5C31;&#x4E0D;&#x8FC7;&#x6EE4;</span>
            <span class="hljs-keyword">if</span> getattr(spider,<span class="hljs-string">&apos;allowed_paths&apos;</span>,<span class="hljs-keyword">None</span>)
                <span class="hljs-keyword">if</span> isinstance(i,scrapy.Request):
                    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> path.startwith(<span class="hljs-string">&apos;/page/&apos;</span>):
                        <span class="hljs-keyword">continue</span>
            <span class="hljs-keyword">yield</span> i

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">RandomUserAgentMiddleware</span><span class="hljs-params">(UserAgentMiddleware)</span>:</span>  <span class="hljs-comment">#&#x4E0B;&#x8F7D;&#x7684;&#x65F6;&#x5019;&#x4F7F;&#x7528;&#x968F;&#x673A;&#x7684;user-agent</span>
<span class="hljs-meta">    @classmethod</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">from_crawler</span><span class="hljs-params">(cls, crawler)</span>:</span>
        <span class="hljs-keyword">return</span> cls(crawler.settings.get(<span class="hljs-string">&apos;USER_AGENT_LIST&apos;</span>,<span class="hljs-keyword">None</span>))
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, user_agent_list)</span>:</span>
        <span class="hljs-keyword">if</span> user_agent_list <span class="hljs-keyword">is</span> <span class="hljs-keyword">None</span>:
            self.agents = [<span class="hljs-string">&apos;scrapy&apos;</span>]
        <span class="hljs-keyword">else</span>:
            self.agents = open(user_agent_list).read().splitlines()
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">process_request</span><span class="hljs-params">(self, request, spider)</span>:</span>
        agent = random.choice(self.agents)
        request.headers[<span class="hljs-string">&quot;User-Agent&quot;</span>] = agent

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ProxyMiddleware</span>:</span>  <span class="hljs-comment">#&#x4E0B;&#x8F7D;&#x542F;&#x7528;&#x4EE3;&#x7406;ip</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">process_request</span><span class="hljs-params">(self,request, spider)</span>:</span>
        request.meta[<span class="hljs-string">&apos;proxy&apos;</span>] = <span class="hljs-string">&quot;http://39.134.10.21:8080&quot;</span>
</code></pre>
<p><strong>setting &#x6587;&#x4EF6;</strong></p>
<pre><code class="lang-python">ITEM_PIPELINES = {
    &#x2018;scrapy.pipelines.images.ImagesPipeline&#x2019;:<span class="hljs-number">1</span>,         <span class="hljs-comment">#&#x542F;&#x7528;&#x56FE;&#x7247;&#x7BA1;&#x9053;</span>
    <span class="hljs-string">&apos;quotes.pipelines.ValidateItem&apos;</span>:<span class="hljs-number">300</span>,
    <span class="hljs-string">&apos;quotes.pipelines.TextWriterPipeline&apos;</span>:<span class="hljs-number">400</span>,
}
SPIDER_MIDDLEWARES = {
    <span class="hljs-string">&apos;quotes.middlewares.FilterOutUrl&apos;</span>:<span class="hljs-number">10000</span>          <span class="hljs-comment">#&#x542F;&#x7528;&#x4E2D;&#x95F4;&#x4EF6;</span>
}
DOWNLOADER_MIDDLEWARES = {                           <span class="hljs-comment">#&#x4E0B;&#x8F7D;&#x4E2D;&#x95F4;&#x4EF6;</span>
    <span class="hljs-string">&apos;scrapy.downloadermiddlewares.useragent.UserAgentMiddleware&apos;</span>:<span class="hljs-number">500</span>,
    <span class="hljs-string">&apos;prox.middlewares.ProxyMiddleware&apos;</span>:<span class="hljs-number">100</span>
}
IMAGES_STORE = <span class="hljs-string">&apos;/tmp/images&apos;</span>                          <span class="hljs-comment">#&#x56FE;&#x7247;&#x5B58;&#x50A8;&#x7684;&#x5730;&#x65B9;</span>
ROBOTSTXT_OBEY = <span class="hljs-keyword">False</span>                               <span class="hljs-comment">#&#x4E0D;&#x9075;&#x5B88;robot</span>
USER = <span class="hljs-string">&apos;scrapy&apos;</span>
PASSWORD = <span class="hljs-string">&apos;scrapy&apos;</span>
DATABASE = <span class="hljs-string">&apos;scrapy&apos;</span>
CHARSET = <span class="hljs-string">&apos;utf8&apos;</span>
DATABLE = <span class="hljs-string">&apos;quotes&apos;</span>
USER_AGENT_LIST = <span class="hljs-string">&apos;/tmp/ua_list.txt&apos;</span>
</code></pre>
<p><strong>item &#x6587;&#x4EF6;</strong></p>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> scrapy.item imort Item, Field
<span class="hljs-keyword">from</span> scrapy.loader <span class="hljs-keyword">import</span> ItemLoader
<span class="hljs-keyword">from</span> scrapy.loader.processors <span class="hljs-keyword">import</span> MapCompose, TakeFirst, Identity

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">drop_symbol</span><span class="hljs-params">(text)</span>:</span>
    <span class="hljs-keyword">return</span> text[<span class="hljs-number">1</span>:]
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">urljoin</span><span class="hljs-params">(url,loader_context)</span>:</span>
    response = loader_context[<span class="hljs-string">&apos;response&apos;</span>]
    <span class="hljs-keyword">return</span> response.urljoin(url)
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">QuotesItem</span><span class="hljs-params">(Item)</span>:</span>
    text = scrapy.Field()
    author = scrapy.Field()
    tags = scrapy.Field()
    images = scrapy.Field()                       <span class="hljs-comment">#&#x4E0B;&#x8F7D;&#x56FE;&#x7247;&#x5B58;&#x653E;&#x7684;&#x5730;&#x5740;</span>
    images_urls = scrapy.Field()                     <span class="hljs-comment">#&#x4E0B;&#x8F7D;&#x56FE;&#x7247;&#x5FC5;&#x987B;&#x6709;&#x7684;</span>

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">QuotesItemLoader</span><span class="hljs-params">(ItemLoader)</span>:</span>                <span class="hljs-comment">#&#x5982;&#x679C;scrapy&#x4F7F;&#x7528;loader,&#x6240;&#x4EE5;&#x8FD9;&#x91CC;&#x8981;&#x5B9A;&#x4E49;loader</span>
    default_item_class = QuotesItem
    default_output_processor = TakeFirst()         <span class="hljs-comment">#&#x7B2C;&#x4E00;&#x4E2A;&#x6709;&#x6548;&#x503C;</span>
    tags_in = MapCompose(<span class="hljs-keyword">lambda</span> x: x.split(<span class="hljs-string">&apos;,&apos;</span>))   <span class="hljs-comment">#&#x5217;&#x8868;</span>
    tags_out = Identity()                             <span class="hljs-comment">#&#x539F;&#x6837;&#x8F93;&#x51FA;</span>
    image_urls_in = MapCompose(urljoin)
    image_urls_out = Identity()                    <span class="hljs-comment">#&#x539F;&#x6837;&#x8F93;&#x51FA;</span>
    title_in = MapCompose(str.strip)
    price_in = MapCompose(drop_symbol,float)       <span class="hljs-comment">#&#x5BF9;&#x722C;&#x53D6;&#x7684;&#x6570;&#x636E;&#x683C;&#x5F0F;&#x5316;&#x8F93;&#x5165;item</span>
</code></pre>
<p><strong>scrapy&#x9879;&#x76EE;&#x6587;&#x4EF6;</strong></p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> scrapy
<span class="hljs-keyword">from</span> quotes.items <span class="hljs-keyword">import</span> QuotesItem&#xFF0C;QuotesItemLoader

<span class="hljs-keyword">from</span> scrapy.shell <span class="hljs-keyword">import</span> inspect_response  <span class="hljs-comment">#&#x8C03;&#x8BD5;&#x6A21;&#x5757;&#xFF0C;&#x5728;&#x4EE3;&#x7801;&#x8FD0;&#x884C;&#x7684;&#x65F6;&#x5019;</span>
inspect_response(response,self)

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">proxSpider</span><span class="hljs-params">(scrapy.Spider)</span>:</span>  <span class="hljs-comment">#&#x5728;&#x8FD0;&#x884C;&#x7A0B;&#x5E8F;&#x4E2D;&#x52A0;&#x53C2;&#x6570;</span>
    name = <span class="hljs-string">&apos;prox&apos;</span>
    start_urls = [<span class="hljs-string">&apos;http://www.gnu.org/&apos;</span>]
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">start_reqests</span><span class="hljs-params">(self)</span>:</span>
        target = getattr(self, <span class="hljs-string">&apos;target&apos;</span>, self.start_urls[<span class="hljs-number">0</span>])
        print(<span class="hljs-string">&apos;yy: &apos;</span>,self,yy, <span class="hljs-string">&apos;xx&#xFF1A;&apos;</span>,self,xx)
        <span class="hljs-keyword">yield</span> scrapy.Request(target)
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse</span><span class="hljs-params">(self, response)</span>:</span>
        print(<span class="hljs-string">&apos;processing page %s &apos;</span> %response.url)

&#x8FD0;&#x884C;&#xFF1A;
scrapy crawl prox -a target=<span class="hljs-string">&apos;https://www.wikipedia.org/&apos;</span> -a yy=<span class="hljs-number">1</span> -a xx=<span class="hljs-number">1</span>

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">DjangoSpider</span><span class="hljs-params">(scrapy.Spider)</span>:</span>   <span class="hljs-comment">#&#x4F7F;&#x7528;scrapy.FormRequest&#x6A21;&#x62DF;&#x767B;&#x9646;&#x722C;&#x53D6;</span>
    name = <span class="hljs-string">&apos;django&apos;</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">start_requests</span><span class="hljs-params">(self)</span>:</span>
        login_url = <span class="hljs-string">&quot;http://localhost:8000/polls/login/&quot;</span>
        <span class="hljs-keyword">yield</span> scrapy.FormRequest(
            url = login_url,
            formdata={<span class="hljs-string">&apos;username&apos;</span>:<span class="hljs-string">&apos;kyo&apos;</span>,<span class="hljs-string">&apos;password&apos;</span>:<span class="hljs-string">&apos;abc&apos;</span>},
            callback=self.after_port
        )
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">after_port</span><span class="hljs-params">(self,response)</span>:</span>
        <span class="hljs-keyword">if</span> <span class="hljs-string">&apos; login failed&apos;</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> response.text:
            self.log(<span class="hljs-string">&apos;login successful&apos;</span>)

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">DjangoSpider</span><span class="hljs-params">(scrapy.Spider)</span>:</span> 
<span class="hljs-comment">#&#x4F7F;&#x7528;FormRequest.from_response&#x6A21;&#x62DF;&#x767B;&#x9646;&#x8868;&#x5355;&#x6709;&#x9690;&#x85CF;&#x5B57;&#x6BB5;,&#x767B;&#x9646;&#x540E;&#xFF0C;&#x8DF3;&#x8F6C;questions_list&#x9875;&#x9762;&#xFF0C;&#x518D;&#x722C;&#x53D6;&#x95EE;&#x9898;</span>
    name = <span class="hljs-string">&apos;django&apos;</span>
    start_urls = [<span class="hljs-string">&apos;http://127.0.0.1:8000/amin/login/&apos;</span>]
    question_list_url = <span class="hljs-string">&apos;http://127.0.0.1:8000/admin/polls/question/&apos;</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse</span><span class="hljs-params">(self,response)</span>:</span>
        <span class="hljs-keyword">yield</span> FormRequest.from_response(
            response,
            url = response.url,
            formdata = {<span class="hljs-string">&apos;username&apos;</span>:<span class="hljs-string">&apos;admin&apos;</span>,<span class="hljs-string">&apos;password&apos;</span>:<span class="hljs-string">&apos;abcd/1234&apos;</span>}
            callback=self.after_login
            )
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">after_login</span><span class="hljs-params">(self,response)</span>:</span>
        <span class="hljs-keyword">if</span> <span class="hljs-string">&apos;Log in&apos;</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> response.css(<span class="hljs-string">&apos;title::text&apos;</span>).extract_first():
            <span class="hljs-keyword">yield</span> scrapy.Request(
                self.question_list_url,
                callback=self.parse_question_list
                )
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse_question_list</span><span class="hljs-params">(self,response)</span>:</span>  <span class="hljs-comment">#urljoin&#x6DFB;&#x52A0;href&#x6807;&#x7B7E;&#x751F;&#x6210;&#x5B8C;&#x6574;url</span>
        <span class="hljs-keyword">for</span> href <span class="hljs-keyword">in</span> response.xpath(<span class="hljs-string">&apos;//tr//a/@href&apos;</span>).extract():  
            href = response.urljoin(href)    
            <span class="hljs-keyword">yield</span> scrapy.Request(href,callback=self.extract_data)
        <span class="hljs-keyword">for</span> a <span class="hljs-keyword">in</span> response.xpath(<span class="hljs-string">&apos;//tr//a&apos;</span>):  <span class="hljs-comment">#follow&#x6A21;&#x5757;&#x6839;&#x636E;a&#x6807;&#x7B7E;&#x8DDF;&#x8E2A;&#x751F;&#x6210;&#x5B8C;&#x6574;url,&#x8FD4;&#x56DE;request</span>
            <span class="hljs-keyword">yield</span> response.follow(a, callback=self.extract_data)
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">extract_data</span><span class="hljs-params">(self,response)</span>:</span>
        text = response.xpath(<span class="hljs-string">&apos;//input[@name=&quot;question_text&quot;]/@value&apos;</span>).extract_first()
        date = response.xpath(<span class="hljs-string">&apos;//input[@name=&quot;pub_date_0&quot;]/@value&apos;</span>).extract_first()
        time = response.xpath(<span class="hljs-string">&apos;//input[@name=&quot;pub_date_1&quot;]/@value&apos;</span>).extract_first()
        <span class="hljs-keyword">yield</span> dict(text=text,date=date,time=time)

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MwSpider</span><span class="hljs-params">(scrapy.Spider)</span>:</span>
    name = <span class="hljs-string">&apos;mw&apos;</span>
    start_urls = [<span class="hljs-string">&apos;http://quotes.toscrape.com&apos;</span>]
    allowed_domains = [<span class="hljs-string">&apos;quotes.toscrapy.com&apos;</span>]
    allowed_paths = [<span class="hljs-string">&apos;/page/&apos;</span>,<span class="hljs-string">&apos;/tag/&apos;</span>]
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse</span><span class="hljs-params">(self,response)</span>:</span>     <span class="hljs-comment">#&#x8DDF;&#x8E2A;&#x51FA;&#x6240;&#x6709;a&#x6807;&#x7B7E;&#x4E0B;&#x7684;url</span>
        print(<span class="hljs-string">&apos;parsing page %s&apos;</span> % response.url)
        <span class="hljs-keyword">for</span> a <span class="hljs-keyword">in</span> response.xpath(<span class="hljs-string">&apos;//a&apos;</span>)
            <span class="hljs-keyword">yield</span> response.follow(a)

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">BooksSpider</span><span class="hljs-params">(scrapy.Spider)</span>:</span>   <span class="hljs-comment">#&#x4E0D;&#x4F7F;&#x7528; item loader &#x60C5;&#x51B5;</span>
    name = <span class="hljs-string">&quot;books2&quot;</span>
    allowed_domain = [<span class="hljs-string">&apos;books.toscrapy.com&apos;</span>]
    start_urls = [<span class="hljs-string">&apos;http://books.toscrape.com&apos;</span>]
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse</span><span class="hljs-params">(self,response)</span>:</span>  
        <span class="hljs-keyword">for</span> li <span class="hljs-keyword">in</span> response.xpath(<span class="hljs-string">&apos;//ol/li&apos;</span>):
            title = li.xpath(<span class="hljs-string">&apos;.//h3/a/text()&apos;</span>).extract_first()
            price = li.css(<span class="hljs-string">&apos;.price_color::text&apos;</span>).extract_first()
            price = float(price[<span class="hljs-number">1</span>:])
            image_url = li.css(<span class="hljs-string">&apos;img::attr(src)&apos;</span>).extract_first()
            image_url = response.ruljoin(image_url)
            image_urls = [image_url]
            <span class="hljs-keyword">yield</span> dict(title = title,price=price,image_urls=image_urls)

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">BasicSpider</span><span class="hljs-params">(scrapy.Spider)</span>:</span>
    name = <span class="hljs-string">&quot;basic&quot;</span>
    allow_domains = [<span class="hljs-string">&quot;quotes.com&quot;</span>]
    start_urls = [
        <span class="hljs-string">&quot;http://quotes.toscrape.com&quot;</span>
    ]
    <span class="hljs-comment">#&#x4F7F;&#x7528;crawlSpider &#x5B9E;&#x73B0;&#x53CC;&#x5411;&#x722C;&#x53D6;&#xFF0C;&#x7EE7;&#x627F;CrawlSpider,&#x800C;&#x4E0D;&#x662F;Spider</span>
    pattern1 = restrict_xpaths=<span class="hljs-string">&apos;//*[contains(@class,&quot;text&quot;)]&apos;</span>
    pagelink1 = LinkExtractor(pattern1)
    pattern2 = restrict_xpaths=<span class="hljs-string">&apos;//*[@itemprop=&quot;url&quot;]&apos;</span>
    pagelink2 = LinkExtractor(pattern2)
    <span class="hljs-comment"># &#x53EF;&#x4EE5;&#x5199;&#x591A;&#x4E2A;rule&#x89C4;&#x5219;</span>
    rules = [
        Rule(pagelink1),
        Rule(pagelink1, callback=<span class="hljs-string">&apos;parse_item&apos;</span>),
    ]
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse</span><span class="hljs-params">(self,response)</span>:</span>
        <span class="hljs-comment">#self.log(&quot;images:%s&quot; % response.xpath(&apos;//img/@src&apos;).extract())</span>
        next_selector = response.xpath(<span class="hljs-string">&apos;//*[contains(@class,&quot;next&quot;)]//@href&apos;</span>)
        <span class="hljs-keyword">for</span> url <span class="hljs-keyword">in</span> next_selector.extract():
            <span class="hljs-keyword">yield</span> scrapy.requests(response.urljson(url))

        item_selector = response.xpath(<span class="hljs-string">&apos;//*[@itemprop=&quot;url&quot;]/@href&apos;</span>)
        <span class="hljs-keyword">for</span> url <span class="hljs-keyword">in</span> item_selector.extract():
            <span class="hljs-keyword">yield</span> scrapy.requests(response.urljson(url),callback=self.parse_item)
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse_item</span><span class="hljs-params">(self,url)</span>:</span>  <span class="hljs-comment">#&#x4F7F;&#x7528; item loader</span>
        <span class="hljs-keyword">for</span> quote <span class="hljs-keyword">in</span> response.xpath(<span class="hljs-string">&apos;//div[@class=&quot;quote&quot;]&apos;</span>):
            l = QuotesItemLoader(selector=quote,response=response)
            l.add_xpath(<span class="hljs-string">&apos;text&apos;</span>,<span class="hljs-string">&apos;.//span[@class=&quot;text&quot;]/text()&apos;</span>)
            l.add_xpath(<span class="hljs-string">&apos;author&apos;</span>,<span class="hljs-string">&apos;.//small[@class=&quot;author&quot;]/text()&apos;</span>)
            l.add_xpath(<span class="hljs-string">&apos;tags&apos;</span>,<span class="hljs-string">&apos;.//meta[@class=&quot;keywords&quot;]/text()&apos;</span>)
            <span class="hljs-keyword">yield</span> l.load_item()

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">StackSpider</span><span class="hljs-params">(scrapy.Spider)</span>:</span>  <span class="hljs-comment">#&#x4ECE;&#x591A;&#x7F51;&#x9875;&#x722C;&#x53D6;&#x4FE1;&#x606F;,&#x7EC4;&#x5408;&#x6210;&#x4E00;&#x4E2A;item</span>
    name = <span class="hljs-string">&apos;stack&apos;</span>
    start_urls = [<span class="hljs-string">&apos;https://stackoverflow.com/?tab=month&apos;</span>]
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse</span><span class="hljs-params">(self, response)</span>:</span>
        <span class="hljs-keyword">for</span> div <span class="hljs-keyword">in</span> response.css(<span class="hljs-string">&apos;div.question-summary&apos;</span>):
            title = div.css(<span class="hljs-string">&apos;div.summary h3 a::text&apos;</span>).extract_first()
            tags = div.css(<span class="hljs-string">&apos;div.summary .tags a ::text&apos;</span>).extract()
            mtime = div.css(<span class="hljs-string">&apos;div.summary .relativetime::attr(title)&apos;</span>).extract_first()
            many = div.css(<span class="hljs-string">&apos;.cp div.mini-counts span::attr(title)&apos;</span>).extract()
            vite, answer,view = [int(x.split()[]) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> many]
            item = dict(title=title,tags=tags,mtime=mtime,vote=vote,
                        answer=answer,view=view)
            anchor = div.css(<span class="hljs-string">&apos;div.summary h3 a&apos;</span>)[<span class="hljs-number">0</span>]
            <span class="hljs-keyword">yield</span> response.follow(anchor,meta={<span class="hljs-string">&apos;item&apos;</span>:item},callback=self.get_dateil)
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_detail</span><span class="hljs-params">(self,response)</span>:</span>
        item = response.meta[<span class="hljs-string">&apos;item&apos;</span>]
        texts = response.css(<span class="hljs-string">&apos;div.post-text&apos;</span>)[<span class="hljs-number">0</span>].css(<span class="hljs-string">&apos;*:text&apos;</span>).extract()
        detail = <span class="hljs-string">&apos;&apos;</span>.join(texts)
        item[<span class="hljs-string">&apos;detail&apos;</span>] = detail 
        <span class="hljs-keyword">yield</span> item

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">UaSpiderSlow</span><span class="hljs-params">(scrapy.Spider)</span>:</span>  <span class="hljs-comment">#&#x6162;&#x6162;&#x722C;&#x540C;&#x4E00;&#x4E2A;&#x7F51;&#x9875;</span>
    name = <span class="hljs-string">&apos;slow&apos;</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">start_requests</span><span class="hljs-params">(self)</span>:</span>
        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">2000</span>):
            print(<span class="hljs-string">&apos;yidlding %s request&apos;</span> %i)
            <span class="hljs-keyword">yield</span> Request(<span class="hljs-string">&apos;http://quotes.toscrape.com/page/1/?round=%s&apos;</span> %i,
                            meta={<span class="hljs-string">&apos;i&apos;</span>:i})
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse</span><span class="hljs-params">(self, response)</span>:</span>
        print(<span class="hljs-string">&apos;processing page %s&apos;</span>%response.meta[<span class="hljs-string">&apos;i&apos;</span>])

setting: 
    DOWNLOAD_DELAY = <span class="hljs-number">1</span>  <span class="hljs-comment">#&#x4E0B;&#x8F7D;&#x5EF6;&#x8FDF; 1*0.5s~1*1.5s &#x4E4B;&#x95F4;&#xFF0C;&#x6A21;&#x5757;&#x4E0D;&#x5EF6;&#x8FDF;</span>

<span class="hljs-comment">#&#x901A;&#x8FC7;telnet console&#x63A7;&#x5236;&#x722C;&#x53D6;&#x72B6;&#x6001;:telnet localhost 6023    </span>
    est()                  &#x722C;&#x53D6;&#x72B6;&#x6001;
    engine.pause()      &#x6682;&#x505C;
    enginge.paused()    &#x6682;&#x505C;&#x72B6;&#x6001;
    enginge.unpause(&#xFF09;  &#x4E0D;&#x6682;&#x505C;
    engine.stop()       &#x505C;&#x6B62;

<span class="hljs-comment">#&#x5B58;&#x50A8;&#x722C;&#x866B;&#x4EFB;&#x52A1;&#x4FE1;&#x606F;&#x3002;time &#x663E;&#x793A;&#x8FD0;&#x884C;&#x65F6;&#x95F4;</span>
    mkdir jobs
    time scrapy crawl slow -s JOBDIR=jobs -s DOWNLOAD_DELAY=<span class="hljs-number">1</span> --nolog

<span class="hljs-comment">#&#x901A;&#x8FC7;Splash&#x5BB9;&#x5668;&#x6E32;&#x67D3;JS&#x7F51;&#x9875;&#x722C;&#x53D6;&#x6570;&#x636E;&#xFF0C;&#x5B89;&#x88C5;docker&#x548C;scrapy-splash&#x6A21;&#x5757;</span>
    docker pull scrapinghub/splash
    docker run -d --name splash -p <span class="hljs-number">8050</span>:<span class="hljs-number">8050</span> scrapinghub/splash
    pip install scrapy-splash

<span class="hljs-comment">#&#x914D;&#x7F6E;setting&#x9ED8;&#x8BA4;&#x9879;</span>
    SPLASH_URL = <span class="hljs-string">&apos;http://localhost:8050&apos;</span>
    DOWNLOADER_MIDDLEWARES = {
        <span class="hljs-string">&apos;scrapy_splash.SplashCookiesMiddleware&apos;</span>:<span class="hljs-number">723</span>,
        <span class="hljs-string">&apos;scrapy_splash.SplashMiddleware&apos;</span>:<span class="hljs-number">725</span>,
        <span class="hljs-string">&apos;scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddle&apos;</span>:<span class="hljs-number">810</span>,
        }
    SPIDER_MIDDLEWARES = {
        <span class="hljs-string">&apos;scrapy_splash.SplashDeduplicateArgsMiddleware&apos;</span>:<span class="hljs-number">100</span>,
        }
    DUPEFILTER_CLASS = <span class="hljs-string">&apos;scrapy_splash.SplashAwareDupeFilter&apos;</span>
    HTTPCACHE_STORAGE = <span class="hljs-string">&apos;scrapy_splash.SplashAwareFSCacheStorage&apos;</span>

<span class="hljs-comment">#&#x5728;spider&#x9879;&#x76EE;&#x4E2D;&#x6DFB;&#x52A0;start_requests&#x65B9;&#x6CD5;</span>
<span class="hljs-keyword">from</span> scrapy_splash <span class="hljs-keyword">import</span> SplashRequest
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">start_requests</span><span class="hljs-params">(self)</span>:</span>
    <span class="hljs-keyword">for</span> url <span class="hljs-keyword">in</span> self.start_urls:
        yidle SplashRequest(url,self.parse)
</code></pre>
<p><strong>scrapy &#x4F7F;&#x7528; selenium &#x722C;&#x53D6;&#x7F51;&#x9875;</strong></p>
<p><strong>scrapy &#x5206;&#x5E03;&#x5F0F;&#x722C;&#x866B;</strong></p>
<p>&#x5927;&#x795E;&#x7B14;&#x8BB0;
<a href="http://www.cnblogs.com/zhaof/tag/%E7%88%AC%E8%99%AB/default.html?page=2" target="_blank">http://www.cnblogs.com/zhaof/tag/%E7%88%AC%E8%99%AB/default.html?page=2</a></p>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="django.html" class="navigation navigation-prev " aria-label="Previous page: django">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="class.html" class="navigation navigation-next " aria-label="Next page: class">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"scrapy","level":"1.12","depth":1,"next":{"title":"class","level":"1.13","depth":1,"path":"python/class.md","ref":"python/class.md","articles":[]},"previous":{"title":"django","level":"1.11","depth":1,"path":"python/django.md","ref":"python/django.md","articles":[]},"dir":"ltr"},"config":{"plugins":[],"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"pluginsConfig":{"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"theme":"default","decription":null,"pdf":{"pageBreaksBefore":"/","headerTemplate":null,"paperSize":"a4","margin":{"right":62,"left":62,"top":36,"bottom":36},"fontSize":12,"fontFamily":"Arial","footerTemplate":null,"chapterMark":"pagebreak","pageNumbers":false},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"isbn":"felix","variables":{},"title":"felix","links":{"sharing":{"all":null,"facebook":null,"google":null,"twitter":null,"weibo":null},"sidebar":{}},"gitbook":"*","extension":null},"file":{"path":"python/scrapy.md","mtime":"2019-03-22T11:22:33.002Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2019-09-27T03:34:11.160Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

